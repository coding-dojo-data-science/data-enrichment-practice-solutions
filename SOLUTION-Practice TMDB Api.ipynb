{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2e3a3c-c4fb-4beb-8578-fe05e8ebe3b4",
   "metadata": {},
   "source": [
    "# TMDB API (Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ad1af-4e6e-41df-b5db-363298895ca9",
   "metadata": {},
   "source": [
    "\n",
    "<p>This practice assignment will reinforce important learning objectives from the previous lesson(s), and allow you to take on more challenging core assignments, preparing you for graduation.<br></p>\n",
    "<p>Practice and tinker with this assignment until you're comfortable performing each of the tasks. Then, be sure to submit your output as described in the steps below.</p>\n",
    "<hr>\n",
    "<h2>TMDB API (Practice):</h2>\n",
    "<h4><strong>Project Planning</strong></h4>\n",
    "<p>As discussed in the previous lesson, for the next part of your project, you will extract financial and certification data from TMDB's API for your IMDB data set. You will use an OUTER and INNER loop: a loop within a loop!</p>\n",
    "<p><strong>The OUTER loop will loop through the start years included in the IMDB data, filter the title basics data </strong>for the selected year, and save the list of movie ids from that year to retrieve in the inner loop.  </p>\n",
    "<p><strong>The INNER loop loops through every movie id from the selected year, extracts its results from the TMDB API, </strong>and appends them to a JSON file.</p>\n",
    "<hr>\n",
    "<h2><span style=\"background-color: initial; font-family: Gotham-Rounded-Bold;\">For this practice assignment</span></h2>\n",
    "<p>You will be practicing the inner loop of API calls for a single year's list of movies from your IMDB title basics data. Specifically, you will extract the API results for every movie with a startYear of 2000.<span style=\"text-decoration-line: line-through;\"><br></span></p>\n",
    "<ul><li><strong>Read the instructions below, including the examples in the \"Getting Started\" section, before starting your work.</strong></li></ul>\n",
    "<hr>\n",
    "<ul><li><strong>Create a new notebook in your project repository called \"Practicing TMDB API calls.\"</strong></li></ul>\n",
    "<p><span style=\"background-color: initial; color: rgb(62, 78, 90); font-family: Gotham-Rounded-Bold; font-size: 16px; font-weight: 700;\">Preparation BEFORE the Loop:</span></p>\n",
    "<ul><li>Designate a folder to save your information.</li><li>Define custom functions you will use for your API calls</li><li>Load your cleaned title basics data from Part 1 of Project 2 (or query your title_basics table in your MySQL database).</li><li>Define the year you wish to retrieve (2000) and create an empty list for appending error messages.</li></ul>\n",
    "<p><br><span style=\"background-color: initial; color: rgb(62, 78, 90); font-family: Gotham-Rounded-Bold; font-size: 16px; font-weight: 700;\">Prepare the DataFrame and JSON File</span><br></p>\n",
    "<ul>\n",
    "<li>\n",
    "<p><strong>Use the selected year to define filenames and filter the data</strong></p>\n",
    "<ol>\n",
    "<li>Define a JSON_FILE filename to save the results in progress.\n",
    "</li><li>Check if the file exists.<ul><li>if it does not exist, create the empty JSON file with <code>with open</code> that just contains the key \"imdb_id\"</li><li>if it exists, print a message saying that it already exists.</li></ul></li></ol></li></ul>\n",
    "<p><u>Now that the JSON file for the results in progress exists:</u></p>\n",
    "<ul><li>Filter the IMDB title basics data for the selected year and save the movie IDs from that year as \"movies_ids\".</li><li>Check the JSON file for previously downloaded movie IDs and filter out the movie ids that already exists in the JSON file ( to prevent duplicate API calls) by:<ul><li>Loading in the contents of the JSON file pd.read_json.<ul><li>Compare the movie_ids that were in the JSON file to your saved movie_ids_to_get.</li></ul></li><li>Save the final list of \"movie_ids_to_get\" by filtering out movies that already exists in the JSON file.</li></ul></li></ul>\n",
    "<h3>Perform the Loop of API Calls</h3>\n",
    "<p>Note: you have already written a function to combine the certification with the rest of the .info() from the TMDB API results in the Intro to TMDB API lesson.</p>\n",
    "<p><strong>Create a loop to make API calls for each id</strong> in the YEAR specified. Include a progress bar using tqdm_notebook</p>\n",
    "<div>\n",
    "<p><u>For each movie id:</u></p>\n",
    "<ul><li>Extract the current ID from the API and retrieve the dictionary of results</li><li>Append the new results to the list from the JSON file</li><li>Save the updated JSON file back to the disk</li></ul>\n",
    "<h3>Save the Results to Compressed .csv </h3>\n",
    "<ul>\n",
    "<li>\n",
    "<p><strong>After the loop,</strong> save the final results for the year as a csv.gz file with the year in the filename.</p>\n",
    "</li></ul>\n",
    "<p>Note: at this point, you'll have completed the inner loop that you will need for the next part of the project.</p>\n",
    "<p><br></p>\n",
    "<hr>\n",
    "<h1>Getting Started</h1><p><span style=\"background-color: initial; color: rgb(62, 78, 90); font-family: Gotham-Rounded-Bold; font-size: 16px; font-weight: 700;\">Preparation BEFORE the Loop:</span><span style=\"background-color: initial; color: rgb(62, 78, 90); font-family: Gotham-Rounded-Bold; font-size: 16px; font-weight: 700;\"></span></p><h4>Designate a folder</h4>\n",
    "<p>You will save API call data in the data folder you created for project Part 1.</p>\n",
    "<pre data-language=\"python\" class=\"active_pre rainbow\"># Import packages\n",
    "import os, time, json\n",
    "import tmdbsimple as tmdb \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "# Create the folder for saving files (if it doesn't exist)\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)</pre>\n",
    "<p>If you created the data folder for part 1, you will see your csv files listed here. If not, it will just be empty [].</p>\n",
    "<pre>['title_basics.csv','title_ratings.csv']\n",
    "</pre>\n",
    "<h4>Define Your Functions</h4>\n",
    "<p>You should ultimately put any custom functions at the top of your notebook. You can first write them where you first use them in your project, but once you have the functions completed and tested, you should move their definitions to the top of your notebook after you import your packages. </p>\n",
    "<p>You will need your function to get the movie rating from the prior lesson, as well as the new function below: write_json. This is a modified version of a function from <a href=\"https://www.geeksforgeeks.org/append-to-json-file-using-python/\" target=\"_blank\">https://www.geeksforgeeks.org/append-to-json-file-using-python/</a>. Notice that the original source link is included in the function's docstring to give proper credit to the original authors.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\">def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) &amp; (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)</pre>\n",
    "<h3></h3><h4>Confirm Your API Function works! </h4><p><span style=\"background-color: initial;\">In order to ensure your function for extracting movie data from TMDB is working, test your function on these 2 movie ids: tt0848228 (\"The Avengers\") and tt0332280 (\"The Notebook\"). Make sure that your function runs without error and that it returns the correct movie's data for both test ids.</span></p><p></p><h4>Load in the Cleaned Title Basics data</h4><p>You need to read in the filtered dataframe you created based on the specification of Project 2 Part 1.</p>\n",
    "<p>You will be filtering out the movies for each year inside the loop, so we will need this loaded and ready to be filtered.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\"># Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('YOUR PATH')\n",
    "</pre>\n",
    "<h4>Define a variable with the  year to Extract from the API</h4>\n",
    "<p>We have data from 2000 - 2020 available. For this assignment, you will just retrieve data for the year 2000. We will save the year as a variable so that we can easily reuse it within our code and also our filenames.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\">YEAR = 2000\n",
    "</pre>\n",
    "<ul><li><strong>Define an errors list</strong></li></ul>\n",
    "<p>We will want to be able to save the ids and error messages for any movie that causes an error. To do so, we will want to create an empty errors list before our loops that we can append to later.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\">errors = [ ]\n",
    "</pre>\n",
    "<h2>Prepare the DataFrame and JSON File</h2><div><div>\n",
    "<ul><li><strong>Select a JSON_FILE filename to save the results in progress.</strong></li></ul><p>First, define the file path, including the year. For the project, you are going to have multiple files, one for each year of movies. The code below will identify the folder in the FOLDER we just defined above and will name the file based on the current year.</p>\n",
    "<pre class=\"rainbow\" data-language=\"python\">#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'</pre>\n",
    "<ul>\n",
    "<li><strong>Determine if the JSON file exists:</strong></li></ul><p>Check if that file already exists or not. If you are going through this lesson for the first time, it is very unlikely that the file exists! But, if you are at a different point in the project, and it already exists, we don't need to do anything, but just make sure it is a file you want to add to!\n",
    "</p>\n",
    "<pre class=\"rainbow\" data-language=\"python\"># Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)</pre>\n",
    "<ul><li><u>If it does not exist:\n",
    "</u><ul><li>Print f\"Creating {filename} for API results for {YEAR}.\"</li><li>Create an empty JSON file using <code>with open</code> that just contains a dictionary with the key \"imdb_id\" and the value 0.<ul><li>We will be appending to this empty dictionary throughout our calls.</li></ul></li></ul></li></ul><pre class=\"rainbow\" data-language=\"python\"># If it does not exist: create it\n",
    "if file_exists == False:\n",
    "    # Print a message indicating the file is being created \n",
    "    print(f\"Creating {JSON_FILE} for API results for {YEAR}.\")\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)</pre>\n",
    "<ul><li><u>If it already exists:\n",
    "</u><ul><li>Print \"The file {JSON_FILE} already exists.\"</li></ul></li></ul><p><span style=\"background-color: initial; color: rgb(62, 78, 90); font-family: Gotham-Rounded-Bold; font-weight: 700;\">Filter for the selected year and save the movie ids</span><br></p>\n",
    "<p>For the project, you will be breaking up the <code>title_basics</code> data by year. For this practice assignment, we will only be extracted data for the year 2000.</p><p>We will create a new DataFrame by filtering title_basics for the selected YEAR. We will then save the list of movie_ids as a separate variable.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\">#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear'] == YEAR].copy()\n",
    "# saving movie ids to separate variable\n",
    "movie_ids = df['tconst']\n",
    "</pre>\n",
    "<h3><div><br></div>Check previous results and create the final list of movie_ids_to_get</h3><p>You may remember from our lesson on efficient API calls that we are going to build in some safeguards when looping through multiple calls.</p>\n",
    "<ul>\n",
    "<li>Load in any existing API results with pd.read_json</li>\n",
    "<li>Check to see if any of the movie_ids to get are already in the JSON file.</li>\n",
    "<li>Filter out only movies that are missing from the JSON file to use in the loop</li>\n",
    "</ul>\n",
    "<p>The code loads any existing information from the JSON file into a dataframe called the \"previous_df.\" This will start empty, but as you iterate through the loop, it will continue to have more and more information.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\"># Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "</pre>\n",
    "<p><strong>Check for and filter out movie IDs that already exist</strong></p>\n",
    "<p>The next line of code will prevent you from wasting API calls on data you already have. Note that it is defining the ids you are calling in such a way that it excludes any ids that are already present in the previous_df. You may recall that this will also allow you to \"pick up where you left off\" if your API call gets interrupted.</p>\n",
    "<pre data-language=\"python\" class=\"rainbow\"># filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "</pre>\n",
    "<p>Now we have defined the \"movie_ids_to_get\". It includes the ids from our dataframe in the year we are seeking, and it excludes any that we have already made calls for.</p>\n",
    "<p>We will use this list for our loop of API calls.</p><p><br></p>\n",
    "<h2>Start Loop Through Movie IDs</h2><p>Now that we have the filtered list of movie_ids_to_get for the current year, we will now create an inner loop to iterate through the movie_ids_to_get, and for each ID, we will: retrieve the movie info from the TMDB API, append the movie_info dictionary to our JSON_FILE, wait 20 ms to avoid overwhelming the API.</p><h4>Set up Progress Bar</h4>\n",
    "<p>We want to keep track of our progress and ensure our calls are working. The progress bar works within the for statement of the for loop. Note that this will iterate through each year that is defined in the YEARS_TO_GET variable.</p>\n",
    "<pre class=\"rainbow\" data-language=\"python\"># Loop through movie_ids_to_get with a tqdm progress bar\n",
    "for movie_id in tqdm_notebook(movie_ids_to_get, f\"Movies from {YEAR}\"):\n",
    "</pre>\n",
    "<p>Ultimately we will be creating a loop, but let's explore each piece of the code:</p>\n",
    "<h2>Iterate through the list of Movie IDs and make the calls</h2>\n",
    "<p>The code below relies on the function you wrote in the previous lesson that made API calls and added the certification to the .info results. Here this function is named \"get_movie_with_rating\". Make sure you have the function from the earlier lesson in the code file before you plan to call on it! This loop also uses the function above (write_json) to extend/append the results to the .json file. <strong>Make sure both functions are defined in your code file before you try to call them!</strong></p><p>Since some movies exist in IMDB's title basics dataset (our DataFrame) that do not exist within the database for TMDB's API, we will get an error whenever we attempt to retrieve a movie id that TMDB does not have in its database. </p><p>To get around this, we will use a try and except statement around our API extraction code. We will TRY to retrieve and save the data for the current movie_id, but if we get an error, we will save the movie_id and error message in our errors list.</p><pre data-language=\"python\" class=\"rainbow\">#Get index and movie id from list\n",
    "try:\n",
    "    # Retrieve then data for the movie id\n",
    "    temp = get_movie_with_rating(movie_id)  \n",
    "    # Append/extend results to existing file using a pre-made function\n",
    "    write_json(temp,JSON_FILE)\n",
    "    # Short 20 ms sleep to prevent overwhelming server\n",
    "    time.sleep(0.02)\n",
    "    \n",
    "except Exception as e:\n",
    "    errors.append([movie_id, e])\n",
    "</pre>\n",
    "<h2>After the Loop</h2><ul><li>Print a message reporting back the number of movie ids that caused an error.</li>\n",
    "</ul>\n",
    "<pre data-language=\"python\" class=\"active_pre rainbow\">print(f\"- Total errors: {len(errors)}\")\n",
    "</pre>\n",
    "Once the inner loop through the movie_ids_to_get has finished, we will have all of our results for that year in our JSON_FILE. We now want to save them in a smaller file format.</div><div><h3>Save the year's results as csv.gz file</h3>\n",
    "<p>Once all of the API calls for the current year are made, you should open your .json file with pd.read_json and convert each json file to a compressed csv (\".csv.gz\") to save space. This is done after the loop.</p>\n",
    "<pre data-language=\"python\" class=\"active_pre rainbow\">final_year_df = pd.read_json(JSON_FILE)\n",
    "final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)</pre>\n",
    "<br><hr>\n",
    "<h2></h2><h2>Troubleshooting:</h2>\n",
    "<p>If you get an error message when trying to run pd.read_json, try replacing pd.read_json with the \"read_and_fix_json\" helper function in this repository: <a href=\"https://github.com/coding-dojo-data-science/data-enrichment-helper-functions\">https://github.com/coding-dojo-data-science/data-enrichment-helper-functions</a></p>\n",
    "<pre data-language=\"python\" class=\"rainbow\"># Instead of previous_df=pd.read_json:\n",
    "previous_df = read_and_fix_json(JSON_FILE)\n",
    "</pre>\n",
    "<ul><li><strong>If you are still having issues with a JSON File,</strong> use Jupyter's file browser to locate the JSON file in your repo and delete it.</li></ul><h2>Summary</h2>\n",
    "<p>This lesson exemplifies the importance of planning your complex coding tasks so that you are clear on what you are trying to do in plain language before translating to code. While this lesson shows examples of the some of the code that you may want to use in the next phase of the project, remember it is still up to you to read and understand each step so that you can put together the final product! </p>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e66b1-e51f-4327-8248-f0c41b430d5d",
   "metadata": {},
   "source": [
    "# SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10768f3f-621e-47a5-86dd-b8ec07fcf21e",
   "metadata": {},
   "source": [
    "### Install/Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047c7c42-d3f1-47fd-ac50-b22f2684d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tmdbsimple (only need to run once)\n",
    "# !pip install tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3645eeb2-12db-4128-979a-4f9d166ed70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, json, time\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66705455-84e1-4088-9ae3-4f2358ac686b",
   "metadata": {},
   "source": [
    "### Load TMDB API Key & Add to tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8d2edb-6dda-4034-94de-bdcadb978fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/codingdojo/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6185eef7-2bf8-4de0-aaa8-22e85adfb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tmdbsimple and setting the API_KEY\n",
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9db78c-67fc-482e-9ea5-c553b58ec3c7",
   "metadata": {},
   "source": [
    "### Designate a Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dde44c3-b1bb-4062-974c-03763b48fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', '.ipynb_checkpoints', 'title-basics.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the folder for saving files (if it doesn't exist)\n",
    "FOLDER = \"MovieData/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "\n",
    "# Show the list of files included in the folder\n",
    "sorted(os.listdir(FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c960645-1d29-4ec6-a218-bf31c6cf508d",
   "metadata": {},
   "source": [
    "### Define Your Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99185c15-6483-4051-8611-77d606ecaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    # save the .info .releases dictionaries\n",
    "    movie_info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    \n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            ## save a \"certification\" key in the info dict with the certification\n",
    "            movie_info['certification'] = c['certification']\n",
    "    return movie_info\n",
    "\n",
    "\n",
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8d55b-6299-462f-b31b-224f439e2201",
   "metadata": {},
   "source": [
    "### Load in the cleaned Title Basics (from part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0386e85e-0684-45de-b5be-98105d92e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El tango del viudo y su espejo deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0096056</td>\n",
       "      <td>movie</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86974</th>\n",
       "      <td>tt9914942</td>\n",
       "      <td>movie</td>\n",
       "      <td>Life Without Sara Amat</td>\n",
       "      <td>La vida sense la Sara Amat</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86975</th>\n",
       "      <td>tt9915872</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Last White Witch</td>\n",
       "      <td>My Girlfriend is a Wizard</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>Comedy,Drama,Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86976</th>\n",
       "      <td>tt9916170</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Rehearsal</td>\n",
       "      <td>O Ensaio</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86977</th>\n",
       "      <td>tt9916190</td>\n",
       "      <td>movie</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>Action,Adventure,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86978</th>\n",
       "      <td>tt9916362</td>\n",
       "      <td>movie</td>\n",
       "      <td>Coven</td>\n",
       "      <td>Akelarre</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Drama,History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86979 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst titleType                                       primaryTitle  \\\n",
       "0      tt0035423     movie                                     Kate & Leopold   \n",
       "1      tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "2      tt0069049     movie                         The Other Side of the Wind   \n",
       "3      tt0088751     movie                                  The Naked Monster   \n",
       "4      tt0096056     movie                               Crime and Punishment   \n",
       "...          ...       ...                                                ...   \n",
       "86974  tt9914942     movie                             Life Without Sara Amat   \n",
       "86975  tt9915872     movie                               The Last White Witch   \n",
       "86976  tt9916170     movie                                      The Rehearsal   \n",
       "86977  tt9916190     movie                                          Safeguard   \n",
       "86978  tt9916362     movie                                              Coven   \n",
       "\n",
       "                                   originalTitle  isAdult  startYear  endYear  \\\n",
       "0                                 Kate & Leopold        0     2001.0      NaN   \n",
       "1      El tango del viudo y su espejo deformante        0     2020.0      NaN   \n",
       "2                     The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                              The Naked Monster        0     2005.0      NaN   \n",
       "4                           Crime and Punishment        0     2002.0      NaN   \n",
       "...                                          ...      ...        ...      ...   \n",
       "86974                 La vida sense la Sara Amat        0     2019.0      NaN   \n",
       "86975                  My Girlfriend is a Wizard        0     2019.0      NaN   \n",
       "86976                                   O Ensaio        0     2019.0      NaN   \n",
       "86977                                  Safeguard        0     2020.0      NaN   \n",
       "86978                                   Akelarre        0     2020.0      NaN   \n",
       "\n",
       "       runtimeMinutes                     genres  \n",
       "0                 118     Comedy,Fantasy,Romance  \n",
       "1                  70                      Drama  \n",
       "2                 122                      Drama  \n",
       "3                 100       Comedy,Horror,Sci-Fi  \n",
       "4                 126                      Drama  \n",
       "...               ...                        ...  \n",
       "86974              74                      Drama  \n",
       "86975              97       Comedy,Drama,Fantasy  \n",
       "86976              51                      Drama  \n",
       "86977              95  Action,Adventure,Thriller  \n",
       "86978              92              Drama,History  \n",
       "\n",
       "[86979 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "basics = pd.read_csv('MovieData/title-basics.csv')\n",
    "basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6058d62-7844-4519-ae79-d8eb55386962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year to filter for\n",
    "YEAR = 2000\n",
    "\n",
    "# Create an empty list for saving errors\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed39f4df-6346-4d3d-9061-7bbe367e4c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MovieData/tmdb_api_results_2000.json for API results for year=2000.\n"
     ]
    }
   ],
   "source": [
    "# Define the JSON file to store results for the year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "\n",
    "# Check if the JSON file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "    print(f\"Creating {JSON_FILE} for API results for year={YEAR}.\")\n",
    "    \n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "# If it exists, print a message\n",
    "else:\n",
    "    print(f'The file {JSON_FILE} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b5736f-c24e-4e58-89aa-b8152e9eaa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     tt0113026\n",
       "9     tt0113092\n",
       "11    tt0115937\n",
       "12    tt0116391\n",
       "13    tt0116628\n",
       "Name: tconst, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for movies from selected startYear\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst']\n",
    "movie_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dc8bae-731e-493b-9e98-e71b3a5b398f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_id\n",
       "0        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c64f73-598e-42b9-9d5d-35a534090b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92753b0-d2ad-4fee-9566-9c69f69bd670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077a729215b486ebbcebc876b6066c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2000:   0%|          | 0/1457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through movie_ids_to_get with a tqdm progress bar\n",
    "for movie_id in tqdm_notebook(movie_ids_to_get, f\"Movies from {YEAR}\"):\n",
    "\n",
    "    # Attempt to retrieve then data for the movie id\n",
    "    try:\n",
    "        temp = get_movie_with_rating(movie_id)  #This uses your pre-ma    de function\n",
    "        # Append/extend results to existing file using a pre-made function\n",
    "        write_json(temp,JSON_FILE)\n",
    "        # Short 20 ms sleep to prevent overwhelming server\n",
    "        time.sleep(0.02)\n",
    "\n",
    "    # If it fails,  make a dict with just the id and None for certification.\n",
    "    except Exception as e:\n",
    "        errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3f81a5-1b7a-4e04-809e-e408bb704b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 209\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5c8afa-d93c-4b19-913a-26148cd20407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results to a csv.gz file\n",
    "final_year_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "csv_fname = f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\"\n",
    "final_year_df.to_csv(csv_fname, compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env-ds)",
   "language": "python",
   "name": "dojo-env-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
